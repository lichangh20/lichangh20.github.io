---
layout: archive
permalink: /cv/
author_profile: true
redirect_from:
  - /resume
---

{% include base_path %}

Download [CV](http://lichangh20.github.io/files/CV_ChanghaoLi.pdf)
======

Education
======
* Ph.D. in Computer Science and Engineering, Georgia Institute of Technology, Atlanta, Georgia, USA, 2024-2029 (expected).
* B.Eng. in Computer Science and Technology, Tsinghua University, Beijing, China, 2020-2024.

Academic
======
* **Undergrad GPA**: 3.89 / 4.00.
* **Undergrad Selected Coursework: **Linear Algebra(A), Calculus(A), Introduction to Complex Analysis(**A+**), Foundation of Object-Oriented Programming(A), Assembly Language Programming(A), Fundamentals of Computer Graphics(A), Artificial Neural Networks(A)
* Ph.D.: Advised by Prof. Bo Dai and Prof. Chao Zhang.
* B.Eng.: A member of TSAIL (Tsinghua Statistical Artificial Intelligence & Learning), advised by Prof. Jianfei Chen and Prof. Jun Zhu.
<!-- * Member of TSAIL (Tsinghua Statistical Artificial Intelligence & Learning), advised by Professor Jianfei Chen and Professor Jun Zhu -->

Research Interests
======
* Reinforcement Learning.
* High Efficient Machine Learning, Quantized Neural Networks.
* Pre-training and Parameter-efficient tuning of LLM.

Publications
======
* Haocheng Xi, **Changhao Li**, Jianfei Chen and Jun Zhu. Training Transformers with 4-bit Integers. ([Paper](https://arxiv.org/pdf/2306.11987.pdf))

<!-- Research Experience
======

* Jun 2023 – Present: **Multi-Step Reasoning with Reinforcement Learning**            
  - Advised by Prof. Xiang Ren, USC INK Lab.
  - Investigated systematically how to improve the multi-step reasoning quality with small language model (Llama2-7B); propose a first distillation then reinforcement-learning framework to improve the generation quality; 
  - Co-lead the project
  
   
* Dec 2022 – May 2023: **Training Transformers with 4-bit Integers**
  -  Directed by Prof. Jianfei Chen & Prof. Jun Zhu, TSAIL.
  -  Proposed a 4-bit quantization method to train the transformer models; Use Hadamard Matrix to filter out out-of-distribution data and use leverage sampling to quantize the gradient
  -  Hardware optimization using Cuda C++; utilized its high efficiency on different GPU architectures
  -  Second author. Accepted by Main Track of NeurIPS 2023.
  -  Project selected to THU *Challenge Cup Competition* -->


Awards & Honors
======
* Outstanding Graduates Awards in Dept. of CST, Tsinghua University.(2024)
* Comprehensive Excellence Scholarship, highest scholarship in Dept. of CST, Tsinghua University.(2023)
* Academic Excellence Scholarship, Tsinghua University.(2022)
* Social Worker Excellence Scholarship, Tsinghua University.(2022)
* Second Prize in National Undergraduate Physics Competition, Beijing Physics Society. (2021)
* First Prize in Chinese Mathematics Olympiad.(2019)

Languages
======
Mandarin (Native), English (Fluent)
* TOEFL  108/120 (Reading 28, Listening 29, Speaking 23, Writing 28).
* GRE Verbal Reasoning 155/170, Quantitative Reasoning 170/170, Analytical Writing 4/6.

Skills & Expertise 
======
* Highly self-motivated researcher. 
* Strong interpersonal skills with a good sense of teamwork.
* Programming Skills: Python (PyTorch), C/C++ (Cuda C++), Java, Linux, Rust.
* Rich experience in state-of-the-art deep learning techniques.

Service & Leadership
======
* Member of Table Tennis Team in Dept.of CST, Tsinghua University. 2021-2023
* Member of Student Union in Dept.of CST, Tsinghua University. 2021-2023
* Member of Tsinghua Orienteering Team, Tsinghua University. 2021-2023
* Student Mentor of Tsinghua Summer School (Beijing), Tsinghua University. 2022.
* Class Monitor in Dept. of CST, Tsinghua University. 2024